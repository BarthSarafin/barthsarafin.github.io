# Artificial intelligence - are we just a bunch of scared cave men?
I believe it is my time to take up the feather and write about the issue of artificial intelligence.
We tend to read and listen to what all the important and influential people of modern society have to say.
We read and listen, maybe process the information, sometimes discarding it as "too far away" to be of interest,
sometimes storing it for a time, we might see more suited to think about these things.
As there never is the perfect time, this blog is now my try on creating a time more suited to think about these things.
What better to start than a most controversial and polarizing subject since cloning breached the walls of science, because let's be honest. If we wanted to clone a human, we could.

To start I want to bring up a quote from Star Trek. Made by the Captain of the USS Voyager after years of battling the epitome of artificial intelligence in science-fiction, the Borg.
> Coffee. The finest organic suspension ever devised... I beat the Borg with it.
> - Captain Catherine Janeway

This quote lays the groundwork to my analysis. It shows where technology actually fails. I could get into the whole biochemistry of the brain here, but as not everyone is a former biologist and this is only an introduction, let me simplify. Only an organic, through biological evolution created, mind can process coffee. Sure there are substitutes for technological "coffee", but it is a far more complicated issue. Coffee might enhance our brain's activity, but it is simply the catalyst to do so. The actual cause lies in the evolution. We, in a way, tell our brain to go into defence mode, even though there is no real need for it. We create a sort of _life and death_ situation to enhance our capacity.
I say, this is something a computer or AI would never understand. It would not have the need for such a thing, as it can compute a likely solution faster than it could devise the need for the _danger mode_, the need for coffee.

## Flight as a window to the situation of AI
Today it is normal to be able to cross the oceans within mere hours, soon probably minutes. What we tend to forget is how it all began. We ignore the fact that just a few decades ago, all we were doing is laugh at the brothers Wright for thinking "Man could fly". I bring up this analogy because it shows exactly the problem we are at now with artificial intelligence. The Wright brothers were the first flying enthusiasts to no longer ask how a bird can fly, but why it is able to do so. They were the first to ask the right questions, seek to correct solution. They stopped trying to copy a birds physique and started to grasp the concepts of physics that allow a bird to fly. As all the jetlagged businessmen and -women prove, the brothers Wright were right. Their trail of thought, their skill to shatter common sense and think "outside the box", paved the way for flight.
So who will crush the sound barrier for artificial intelligence and start asking the right questions? It doesn't really matter. What is essential is the change of thought. We need to stop trying to copy the human brain and start to ask why is the brain able to do what it does. How we then try to create our artificial brains is apparent. It is done all around us already, so we just need to look and wait. Deep Learning, neural nets and specific AI brains are conjured up and used all around us, the question is do they already ask the right questions or is it still a try to copy the human brain. To underline my point I would like to leave a quote.

> Turing’s ghost is still with us, directing the energies of our field in certain directions and subtly discouraging others. We traditionally measure the success of AI systems by comparing them to human performance — which is rather like measuring the performance of aircraft against that of birds and complaining that aircraft do not land in trees or soil our automobiles.
> - _Cognitive Orthoses: Toward Human-Centered AI - Kenneth M. Ford, Patrick J. Hayes, Clark Glymour, James Allen_

## The many faces of artificial intelligence
As always the noun we use to talk about something doesn't really describe what we are talking about. It's as if we talk about schizophrenia, we mean multiple personality disorder, but we say schizophrenia. A brutal example, yes, but an important one. We talk about artificial intelligence when we actually are talking only about certain parts of it, that actually do not encompass all the problems or solutions, due to being so much more complicated. There are three distinct areas I want to brush. ANI, AGI and ASI.

### Artificial Narrow intelligence ANI
As the _weak AI_ it has the capability to work only on one specific task. Into this category falls the chess playing and world champion beating machine, for example. Or that annoying voice when you call a bank or hotline is usually an ANI as well. Further more it is important to take into consideration that a _weak AI_ is non sentient, though I will not talk about the sentience of artificial intelligence right now.

### Artificial General Intelligence AGI
The AI on par with human intelligence is the general intelligence or _Strong AI_. The theory of the [Chinese room argument](https://en.wikipedia.org/wiki/Chinese_room#Strong_AI) sheds light on the impossibility of the machine being able to have a sentient intelligence. I am not going to talk about this here. I only want to talk about what is considered a _Strong AI_. It is achieved as soon as the Turing test is passed. The machine and a human talk to another second human. That human is not aware which is the machine and which is the human, but has to evaluate who is who. Another test, to come back to the starting quote, is the Coffee Test. A machine has to make coffee. Not a coffee machine, but a machine with intelligence. It has to be able to enter a home, find the coffee machine, push the correct buttons, add water and coffee beans. The complexity of these tasks might not be as apparent to you right now, but think about it for a while. It is not as easy as it at first appears. We just went through a long process of learning and evolved to be able to process that level of complexity. Which brings me to the important bit. An AGI must be able to learn and reason. Without that it cannot evolve. And only if something can evolve it is truly intelligent. It's the start of becoming or being sentient. Being able to process complex patterns and make them look easy. Think like an individual and flourish on the strength of ones individuality. That is by the way the reason the Borg failed in my opinion, but that is part of another discussion.

### Artificial Super Intelligence ASI
The artificial intelligence can surpass the point where it is more than a mere intelligence. Where it stops being an AGI and becomes more. This Artificial Super Intelligence, ASI, is better as a biological human brain in every facet. What this means is that it is the leading expert in every field, at the same time. Even if it is just a smidge better than everyone else. It still is smarter and better. As Elon Musk says it is the ultimate predator of the human species. Our demon. Our End.
> I’m increasingly inclined to think that there should be some regulatory oversight, maybe at the national and international level, just to make sure that we don’t do something very foolish. I mean with artificial intelligence we’re summoning the demon.
> _Elon Musk warned at MIT’s AeroAstro Centennial Symposium_

It is obvious that this has a certain truth to it. Especially from someone like Elon Musk, as he actually knows what he is talking about. Nonetheless as a less public figure, I say it might be a bit over the top. He has to say it this hard, even though he might not believe it completely. I myself wonder are we a bunch of cavemen huddled up in our homes scared and puddled? Is the future so grave as Papa Elon is painting it or are we more in line with enhancing ourselves as Ginni Rometty puts it.
> Some people call this artificial intelligence, but the reality is this technology will enhance us. So instead of artificial intelligence, I think we'll augment our intelligence.
> — _Ginni Rometty_

## The eclipse of humanity - when the singularity arises
In terms of a danger to humanity, I am not so sure. The Wright brothers were marked as crazy doomsayers by the leaders and public figures of their time. They were laughed at and considered to be "summoning the demons". Sound familiar? As much as I like Elon Musk. Sometimes I wonder on what front he sits. Does he want to further the cause of AI or is he one of those decrying the Wright brothers, I tend to not really see his goal. On one side he says something like this and then goes and creates a self-driving car depending on said technology. Honestly I have no answer yet. I am not sure what his goals are or if he actually is an evil "Bond" villain mastermind with his secret lair on a tropical island and bikini wearing robots.
What I do know is that I believe in the ingenuity of humanity. There is a concept called "Singularity". It describes the moment when humanity is surpassed by its creation, specifically in this case the machine with an artificial super intelligence. The moment an AGI becomes an ASI. Certainly if you believe all the science fiction works or the doomsayers with their cute bunkers and doomsday houses. James Barrat has a point. Even though it might cast a wrong shadow, as the American population always tended to have these [preppers](https://en.wikipedia.org/wiki/Survivalism), be it because of a zombie apocalypse, aliens or super robots. It has to be considered with a certain dent of amusement in my opinion.
> I don’t want to really scare you, but it was alarming how many people I talked to who are highly placed people in AI who have retreats that are sort of 'bug out' houses, to which they could flee if it all hits the fan.
> — _James Barrat, author of Our Final Invention: Artificial Intelligence and the End of the Human Era, told the Washington Post_

Again. I believe in the ingenuity of humanity. Because what all those [Survivalism](https://en.wikipedia.org/wiki/Survivalism) believers and doomsayers forget is, that in all the fiction, it is in the end the human *mind* that trumps (yeah, I did that) over all these apocalyptic scenarios and enemies. Humanity tends to surprise itself, if sufficiently cornered. And how? Mostly by going into _danger mode_. See what I did there? Went full circle.
